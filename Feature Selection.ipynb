{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Introduction: <br>\n",
    "Broadly, there are __three__ categories of methods for __Feature Selection__. <br>\n",
    "1. Filter Methods\n",
    "2. Embedded Methods\n",
    "3. Wrapper Methods.\n",
    "<br>\n",
    "\n",
    "In this jupyter notebook I will be using __Random Forest__ as an __Embedded Method__, __Mutual Information__ as __Filter Method__ and __Recursive Feature Elimination__ as __Wrapper Method__. \n",
    "<br>\n",
    "<br>\n",
    "<a href='https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2'>For more details</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,accuracy_score,confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif,RFE,RFECV,VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics(model, test_X,test_Y):\n",
    "    # 01 predict using model #\n",
    "    prediction = model.predict(test_X)\n",
    "    # 02 accuracy #\n",
    "    accuracy = accuracy_score(test_Y, prediction)*100\n",
    "    # 03 precision #\n",
    "    precision = precision_score(test_Y, prediction,pos_label=1,labels=[1,0])*100\n",
    "    # 04 recall #\n",
    "    recall = recall_score(test_Y, prediction,pos_label=1,labels=[1,0])*100\n",
    "    # 05 confusion Matrix #\n",
    "    cm = confusion_matrix(test_Y, prediction,labels=[1,0])\n",
    "    return accuracy, precision, recall, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, X,y):\n",
    "    train_X,test_X,train_Y, test_Y = train_test_split(X,y)\n",
    "    return train_X,test_X,train_Y, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_X,train_Y):\n",
    "    model.fit(train_X,train_Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(dt):\n",
    "    defaulters = dt[dt['default payment next month']==1]\n",
    "    non_defaulters = dt[dt['default payment next month']==0]\n",
    "    return defaulters,non_defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_payment_status(deafulters, non_defaulters,payment_status):\n",
    "    for status in payment_status:\n",
    "        key =  'updated_'+ status\n",
    "        defaulters[key] = defaulters[status].apply(lambda x: x if x in [-1,1,2,3,4,5,6,7,8,9] else 2 )\n",
    "        non_defaulters[key] = non_defaulters[status].apply(lambda x: x if x in [-1,1,2,3,4,5,6,7,8,9] else -1 )\n",
    "    return deafulters,non_defaulters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01 Fetch the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Facts About Data </u>: \n",
    "1. This research aimed at the case of customers default payments in Taiwan. \n",
    "<br> \n",
    "2. This research employed a binary variable, __default payment (Yes = 1, No = 0), as the response variable__.\n",
    "<br>\n",
    "3. This study reviewed the literature and used the following __23 variables as explanatory variables__.\n",
    "<br>\n",
    "4. __Limit of Balance__: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "<br>\n",
    "5. __Gender__: (1 = male; 2 = female).\n",
    "<br>\n",
    "6. __Education__: (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "<br>\n",
    "7. __Marital status__ (1 = married; 2 = single; 3 = others).\n",
    "<br>\n",
    "8. __Age__ (year).\n",
    "<br>\n",
    "9. __PAY_0 till PAY_6__: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "<br>\n",
    "10. __BILL_AMT1 till BILL_AMT6__: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "<br>\n",
    "11. __PAY_AMT1-PAY_AMT6__: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "<br>\n",
    "<br>\n",
    "<a href='https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients'> For more Information </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_excel('default of credit card clients.xls', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77.88\n",
       "1    22.12\n",
       "Name: default payment next month, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['default payment next month'].value_counts()/len(dt)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Information__: There is __22%__ share of __fraudulent cases__  in the data whereas, the __non-defaulters__ make up to about __78%__ of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embedded Methods\n",
    "__Description__: Feature selection can also be acheived by the insights provided by some Machine Learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with complete data (all features) so, we can see what is the __Feature Importance__ according to __Random Forest__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.69295712, 81.29304599, 81.84444444, 81.50700156, 81.48477439])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.73333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.16309012875536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.59730722154223"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 598, 1036],\n",
       "       [ 334, 5532]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the feature importance according to __Random Forest__? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAY_0        9.876261\n",
       "AGE          6.594053\n",
       "BILL_AMT1    6.039220\n",
       "LIMIT_BAL    5.961639\n",
       "BILL_AMT2    5.469988\n",
       "BILL_AMT3    5.157291\n",
       "PAY_AMT1     5.152024\n",
       "BILL_AMT5    5.026638\n",
       "BILL_AMT4    4.981807\n",
       "BILL_AMT6    4.962905\n",
       "PAY_AMT2     4.826063\n",
       "PAY_AMT3     4.643719\n",
       "PAY_AMT6     4.597552\n",
       "PAY_AMT5     4.398325\n",
       "PAY_AMT4     4.355377\n",
       "PAY_2        4.135263\n",
       "PAY_3        2.614682\n",
       "PAY_4        2.493960\n",
       "PAY_5        2.065524\n",
       "EDUCATION    2.036881\n",
       "PAY_6        2.004002\n",
       "MARRIAGE     1.384056\n",
       "SEX          1.222769\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(trained_model.feature_importances_, index=X.columns.values).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: According to Random Forest the __PAY_0__,  __AGE__, __BILL_AMT1__, __LIMIT_BAL__ and __BILL_AMT2__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Run the __Random Forest__ using __top 5 features__ from features suggested by __feature importance__ of __Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['PAY_0','AGE','BILL_AMT1','LIMIT_BAL','BILL_AMT2']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features suggested by Random Forest feature importance__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.11552988, 80.69317929, 80.04444444, 80.28450767, 81.06245832])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.14666666666666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.082730093071355"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.50118764845605"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 581, 1103],\n",
       "       [ 386, 5430]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __don't improve much after using selected features__ so, we will need to use filter method to get the best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filter Methods \n",
    "__Description__:\n",
    "Filter Methods considers the relationship between features and the target variable to compute the importance of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Mutual Information:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Before Data Cleaning_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['default payment next month'],axis=1)\n",
    "y = dt['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAY_0        7.701669\n",
       "PAY_2        4.462218\n",
       "PAY_3        4.014667\n",
       "PAY_4        3.428443\n",
       "PAY_5        3.227407\n",
       "PAY_6        3.041289\n",
       "PAY_AMT1     2.340312\n",
       "PAY_AMT3     1.751627\n",
       "PAY_AMT5     1.607144\n",
       "PAY_AMT4     1.593538\n",
       "PAY_AMT2     1.440210\n",
       "LIMIT_BAL    1.200238\n",
       "PAY_AMT6     1.074484\n",
       "BILL_AMT1    1.016530\n",
       "BILL_AMT5    0.842754\n",
       "BILL_AMT6    0.778144\n",
       "BILL_AMT3    0.741111\n",
       "EDUCATION    0.679060\n",
       "BILL_AMT2    0.539135\n",
       "ID           0.394234\n",
       "BILL_AMT4    0.305516\n",
       "MARRIAGE     0.285118\n",
       "SEX          0.030395\n",
       "AGE          0.019791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: According to the __Mutual Information__ __PAY_0__, __PAY_2__, __PAY_3__, __PAY_4__  and __PAY_5__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.<u>  Random Forest:</u><br>\n",
    "Running Random Forest with __Selected features suggested by Mutual Information__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['PAY_0','PAY_2','PAY_3','PAY_4','PAY_5']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features suggested by mutual information before cleaning__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.44856699, 81.40413242, 81.33333333, 81.5959102 , 81.97377195])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.89333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.85135135135135"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.34912718204489"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 567, 1037],\n",
       "       [ 321, 5575]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __don't improve much after using selected features__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__:\n",
    "<br>\n",
    "Based on EDA (in other notebook) the consistent trends is observed between __defaulters__ and __non-defaulters__ in __Payment Status__. The __defaulters__ usually delay payment by __two months__ whereas, __non-defaulters__ usually __pay duly__.\n",
    "<br>\n",
    "<br>\n",
    "The legtimate values according to UCI Repository are __ __-1,1,2,3,4,5,6,7,8, and 9__ whereas, it is observed there is significant share of __status 0 and -2__ which aren't valid as per UCI description about data. We can't remove the entries as they make up the major portion of the data. \n",
    "<br>\n",
    "<br>\n",
    "Based on assumption i have replaced invalid status with __2 (assuming they usually delay payment by two months)__ in case of __defaulters__ whereas, in case of __non-defaulters__ the invalid status replaced by __-1 (assuming they usually pay duly)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_After Data Cleaning_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.<u>  Mutual Information After Data Cleaning:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the __defaulters__ and __non-defaulters__ data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulters,non_defaulters = separate_data(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Clean the __Payment status__ i.e replace invalid values with __2 and -1__ in __defaulters__ and __non-defaulters__ (as observed) respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "payment_status = ['PAY_0','PAY_2','PAY_3','PAY_5','PAY_4','PAY_6']\n",
    "defaulters,non_defaulters = clean_payment_status(defaulters,non_defaulters, payment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.concat([defaulters,non_defaulters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. split the dataset for MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the __Mutual Information__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updated_PAY_5    29.375431\n",
       "updated_PAY_6    27.736797\n",
       "updated_PAY_4    27.601670\n",
       "updated_PAY_2    25.598799\n",
       "updated_PAY_3    25.590725\n",
       "updated_PAY_0    24.030481\n",
       "PAY_0             7.628413\n",
       "PAY_2             4.461428\n",
       "PAY_3             3.835841\n",
       "PAY_4             3.238270\n",
       "PAY_5             3.086649\n",
       "PAY_6             2.714388\n",
       "PAY_AMT1          2.677441\n",
       "PAY_AMT3          2.131717\n",
       "PAY_AMT4          1.778382\n",
       "LIMIT_BAL         1.662372\n",
       "PAY_AMT5          1.499841\n",
       "PAY_AMT2          1.471083\n",
       "BILL_AMT1         1.059813\n",
       "PAY_AMT6          1.001190\n",
       "EDUCATION         0.721552\n",
       "BILL_AMT6         0.714375\n",
       "BILL_AMT5         0.642963\n",
       "BILL_AMT3         0.638283\n",
       "BILL_AMT2         0.491247\n",
       "AGE               0.422595\n",
       "BILL_AMT4         0.336962\n",
       "MARRIAGE          0.215574\n",
       "SEX               0.109374\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: __After Data Cleaning__ according to the __Mutual Information__ __updated_PAY_5__, __updated_PAY_6__, __updated_PAY_4__, __updated_PAY_3__  and __updated_PAY_2__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.<u>  Random Forest:</u><br>\n",
    "Re-Running Random Forest with __Selected features using Mutual Information after data cleaning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['updated_PAY_5','updated_PAY_6','updated_PAY_4','updated_PAY_3','updated_PAY_2']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features after data cleaning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([94.00399734, 93.73750833, 93.66666667, 94.73333333, 93.93333333,\n",
       "       94.8       , 94.4       , 95.        , 93.6       , 94.2       ,\n",
       "       95.06666667, 94.6       , 93.4       , 93.86257505, 93.86257505])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=15 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.93333333333334"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.61323155216286"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.4631515877771"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1393,  276],\n",
       "       [ 179, 5652]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __improve significantly after data cleaning__. <br>\n",
    "1. __Recall jumped from 35% to 83%__ \n",
    "2. __Precision jumped 64% to 89%__ \n",
    "3. __Accuracy jumped from 82% to 94%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wrapper Methods\n",
    "__Description__: Wrapper Methods generate models with a subsets of feature and gauge their model performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. <u> Recursive Feature Elimination:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Train Model:<br>\n",
    "Training the model with the complete dataset (all features including the updated payment statuses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Rank the features using RFE (Recursive Feature Elimination):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=100)\n",
    "selector = RFE(estimator=RF_model, step=1, n_features_to_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Check the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[X.columns[rfe.support_].tolist()]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(RF_model, train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92.41333333, 92.54666667, 92.70666667])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=trained_model, X = train_X, y=train_Y,cv=3 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.Validation Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.47999999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.44175044352454"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.24483775811208"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1411,  284],\n",
       "       [ 280, 5525]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __improve a bit in terms of recall whereas other metrics have decreased as compare to filter method which has so far produce the best results__. <br>\n",
    "1. __Recall jumped from 81% to 82%__ \n",
    "2. __Precision decrease 89% to 84%__ \n",
    "3. __Accuracy decrease from 94% to 93%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Store the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: The features suggested by `Filter Method` turned out to be the best set of features in terms of model `accuracy`, `precision` and `recall`so, we opted for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'model.pkl'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
